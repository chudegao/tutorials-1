
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/hyperparameter_tuning_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_hyperparameter_tuning_tutorial.py:


Hyperparameter tuning with Ray Tune
===================================

Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.

Fortunately, there are tools that help with finding the best combination of parameters.
`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through `Ray's distributed machine learning engine
<https://ray.io/>`_.

In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend `this tutorial from the PyTorch documentation
<https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_ for training
a CIFAR10 image classifier.

As you will see, we only need to add some slight modifications. In particular, we
need to

1. wrap data loading and training in functions,
2. make some network parameters configurable,
3. add checkpointing (optional),
4. and define the search space for the model tuning

|

To run this tutorial, please make sure the following packages are
installed:

-  ``ray[tune]``: Distributed hyperparameter tuning library
-  ``torchvision``: For the data transformers

Setup / Imports
---------------
Let's start with the imports:

.. GENERATED FROM PYTHON SOURCE LINES 42-55

.. code-block:: default

    from functools import partial
    import os
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import random_split
    import torchvision
    import torchvision.transforms as transforms
    from ray import tune
    from ray.air import Checkpoint, session
    from ray.tune.schedulers import ASHAScheduler








.. GENERATED FROM PYTHON SOURCE LINES 56-63

Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.

Data loaders
------------
We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.

.. GENERATED FROM PYTHON SOURCE LINES 63-81

.. code-block:: default



    def load_data(data_dir="./data"):
        transform = transforms.Compose(
            [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
        )

        trainset = torchvision.datasets.CIFAR10(
            root=data_dir, train=True, download=True, transform=transform
        )

        testset = torchvision.datasets.CIFAR10(
            root=data_dir, train=False, download=True, transform=transform
        )

        return trainset, testset









.. GENERATED FROM PYTHON SOURCE LINES 82-87

Configurable neural network
---------------------------
We can only tune those parameters that are configurable.
In this example, we can specify
the layer sizes of the fully connected layers:

.. GENERATED FROM PYTHON SOURCE LINES 87-109

.. code-block:: default



    class Net(nn.Module):
        def __init__(self, l1=120, l2=84):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)
            self.pool = nn.MaxPool2d(2, 2)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, l1)
            self.fc2 = nn.Linear(l1, l2)
            self.fc3 = nn.Linear(l2, 10)

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1)  # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x









.. GENERATED FROM PYTHON SOURCE LINES 110-213

The train function
------------------
Now it gets interesting, because we introduce some changes to the example `from the PyTorch
documentation <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html>`_.

We wrap the training script in a function ``train_cifar(config, data_dir=None)``.
The ``config`` parameter will receive the hyperparameters we would like to
train with. The ``data_dir`` specifies the directory where we load and store the data,
so that multiple runs can share the same data source.
We also load the model and optimizer state at the start of the run, if a checkpoint
is provided. Further down in this tutorial you will find information on how
to save the checkpoint and what it is used for.

.. code-block:: python

    net = Net(config["l1"], config["l2"])

    checkpoint = session.get_checkpoint()

    if checkpoint:
        checkpoint_state = checkpoint.to_dict()
        start_epoch = checkpoint_state["epoch"]
        net.load_state_dict(checkpoint_state["net_state_dict"])
        optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

The learning rate of the optimizer is made configurable, too:

.. code-block:: python

    optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.

Adding (multi) GPU support with DataParallel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch's abstractions in Ray Tune. Thus, we can wrap our model in ``nn.DataParallel``
to support data parallel training on multiple GPUs:

.. code-block:: python

    device = "cpu"
    if torch.cuda.is_available():
        device = "cuda:0"
        if torch.cuda.device_count() > 1:
            net = nn.DataParallel(net)
    net.to(device)

By using a ``device`` variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:

.. code-block:: python

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports `fractional GPUs <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We'll come back
to that later.

Communicating with Ray Tune
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The most interesting part is the communication with Ray Tune:

.. code-block:: python

    checkpoint_data = {
        "epoch": epoch,
        "net_state_dict": net.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
    }
    checkpoint = Checkpoint.from_dict(checkpoint_data)

    session.report(
        {"loss": val_loss / val_steps, "accuracy": correct / total},
        checkpoint=checkpoint,
    )

Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.

The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
`Population Based Training <https://docs.ray.io/en/latest/tune/examples/pbt_guide.html>`_.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set. Lastly, saving checkpoints is useful for fault tolerance, and it allows
us to interrupt training and continue training later.

Full training function
~~~~~~~~~~~~~~~~~~~~~~

The full code example looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 213-312

.. code-block:: default



    def train_cifar(config, data_dir=None):
        net = Net(config["l1"], config["l2"])

        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if torch.cuda.device_count() > 1:
                net = nn.DataParallel(net)
        net.to(device)

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=config["lr"], momentum=0.9)

        checkpoint = session.get_checkpoint()

        if checkpoint:
            checkpoint_state = checkpoint.to_dict()
            start_epoch = checkpoint_state["epoch"]
            net.load_state_dict(checkpoint_state["net_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
        else:
            start_epoch = 0

        trainset, testset = load_data(data_dir)

        test_abs = int(len(trainset) * 0.8)
        train_subset, val_subset = random_split(
            trainset, [test_abs, len(trainset) - test_abs]
        )

        trainloader = torch.utils.data.DataLoader(
            train_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )
        valloader = torch.utils.data.DataLoader(
            val_subset, batch_size=int(config["batch_size"]), shuffle=True, num_workers=8
        )

        for epoch in range(start_epoch, 10):  # loop over the dataset multiple times
            running_loss = 0.0
            epoch_steps = 0
            for i, data in enumerate(trainloader, 0):
                # get the inputs; data is a list of [inputs, labels]
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward + backward + optimize
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                running_loss += loss.item()
                epoch_steps += 1
                if i % 2000 == 1999:  # print every 2000 mini-batches
                    print(
                        "[%d, %5d] loss: %.3f"
                        % (epoch + 1, i + 1, running_loss / epoch_steps)
                    )
                    running_loss = 0.0

            # Validation loss
            val_loss = 0.0
            val_steps = 0
            total = 0
            correct = 0
            for i, data in enumerate(valloader, 0):
                with torch.no_grad():
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)

                    outputs = net(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                    loss = criterion(outputs, labels)
                    val_loss += loss.cpu().numpy()
                    val_steps += 1

            checkpoint_data = {
                "epoch": epoch,
                "net_state_dict": net.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
            }
            checkpoint = Checkpoint.from_dict(checkpoint_data)

            session.report(
                {"loss": val_loss / val_steps, "accuracy": correct / total},
                checkpoint=checkpoint,
            )
        print("Finished Training")









.. GENERATED FROM PYTHON SOURCE LINES 313-320

As you can see, most of the code is adapted directly from the original example.

Test set accuracy
-----------------
Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:

.. GENERATED FROM PYTHON SOURCE LINES 320-343

.. code-block:: default



    def test_accuracy(net, device="cpu"):
        trainset, testset = load_data()

        testloader = torch.utils.data.DataLoader(
            testset, batch_size=4, shuffle=False, num_workers=2
        )

        correct = 0
        total = 0
        with torch.no_grad():
            for data in testloader:
                images, labels = data
                images, labels = images.to(device), labels.to(device)
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total









.. GENERATED FROM PYTHON SOURCE LINES 344-402

The function also expects a ``device`` parameter, so we can do the
test set validation on a GPU.

Configuring the search space
----------------------------
Lastly, we need to define Ray Tune's search space. Here is an example:

.. code-block:: python

    config = {
        "l1": tune.choice([2 ** i for i in range(9)]),
        "l2": tune.choice([2 ** i for i in range(9)]),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

The ``tune.choice()`` accepts a list of values that are uniformly sampled from.
In this example, the ``l1`` and ``l2`` parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The ``lr`` (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.

At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the ``ASHAScheduler`` which will terminate bad
performing trials early.

We wrap the ``train_cifar`` function with ``functools.partial`` to set the constant
``data_dir`` parameter. We can also tell Ray Tune what resources should be
available for each trial:

.. code-block:: python

    gpus_per_trial = 2
    # ...
    result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 8, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        checkpoint_at_end=True)

You can specify the number of CPUs, which are then available e.g.
to increase the ``num_workers`` of the PyTorch ``DataLoader`` instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven't been requested for them - so you don't have to care about two trials
using the same set of resources.

Here we can also specify fractional GPUs, so something like ``gpus_per_trial=0.5`` is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.

After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.

The full main function looks like this:

.. GENERATED FROM PYTHON SOURCE LINES 402-455

.. code-block:: default



    def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
        data_dir = os.path.abspath("./data")
        load_data(data_dir)
        config = {
            "l1": tune.choice([2**i for i in range(9)]),
            "l2": tune.choice([2**i for i in range(9)]),
            "lr": tune.loguniform(1e-4, 1e-1),
            "batch_size": tune.choice([2, 4, 8, 16]),
        }
        scheduler = ASHAScheduler(
            metric="loss",
            mode="min",
            max_t=max_num_epochs,
            grace_period=1,
            reduction_factor=2,
        )
        result = tune.run(
            partial(train_cifar, data_dir=data_dir),
            resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
            config=config,
            num_samples=num_samples,
            scheduler=scheduler,
        )

        best_trial = result.get_best_trial("loss", "min", "last")
        print(f"Best trial config: {best_trial.config}")
        print(f"Best trial final validation loss: {best_trial.last_result['loss']}")
        print(f"Best trial final validation accuracy: {best_trial.last_result['accuracy']}")

        best_trained_model = Net(best_trial.config["l1"], best_trial.config["l2"])
        device = "cpu"
        if torch.cuda.is_available():
            device = "cuda:0"
            if gpus_per_trial > 1:
                best_trained_model = nn.DataParallel(best_trained_model)
        best_trained_model.to(device)

        best_checkpoint = best_trial.checkpoint.to_air_checkpoint()
        best_checkpoint_data = best_checkpoint.to_dict()

        best_trained_model.load_state_dict(best_checkpoint_data["net_state_dict"])

        test_acc = test_accuracy(best_trained_model, device)
        print("Best trial test set accuracy: {}".format(test_acc))


    if __name__ == "__main__":
        # You can change the number of GPUs per trial here:
        main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz

      0% 0/170498071 [00:00<?, ?it/s]
      0% 458752/170498071 [00:00<00:37, 4581745.71it/s]
      2% 4161536/170498071 [00:00<00:07, 23608423.08it/s]
      5% 8257536/170498071 [00:00<00:05, 31476369.87it/s]
      7% 12615680/170498071 [00:00<00:04, 36218066.78it/s]
     10% 16744448/170498071 [00:00<00:04, 37898947.60it/s]
     12% 21037056/170498071 [00:00<00:03, 39424151.73it/s]
     15% 25362432/170498071 [00:00<00:03, 40659777.64it/s]
     17% 29491200/170498071 [00:00<00:03, 40834243.33it/s]
     20% 33849344/170498071 [00:00<00:03, 41544634.54it/s]
     22% 38010880/170498071 [00:01<00:03, 41298554.55it/s]
     25% 42237952/170498071 [00:01<00:03, 41587324.62it/s]
     27% 46530560/170498071 [00:01<00:02, 41880880.12it/s]
     30% 50757632/170498071 [00:01<00:02, 41791198.29it/s]
     32% 55017472/170498071 [00:01<00:02, 41910065.94it/s]
     35% 59211776/170498071 [00:01<00:02, 41584408.92it/s]
     37% 63406080/170498071 [00:01<00:02, 41630036.00it/s]
     40% 68157440/170498071 [00:01<00:02, 43361775.60it/s]
     45% 76251136/170498071 [00:01<00:01, 54522641.68it/s]
     50% 84475904/170498071 [00:01<00:01, 62753485.33it/s]
     54% 92864512/170498071 [00:02<00:01, 69029754.88it/s]
     59% 101351424/170498071 [00:02<00:00, 73767386.23it/s]
     64% 109871104/170498071 [00:02<00:00, 77047914.17it/s]
     70% 118554624/170498071 [00:02<00:00, 79955571.07it/s]
     75% 127270912/170498071 [00:02<00:00, 82090905.61it/s]
     80% 135987200/170498071 [00:02<00:00, 83535597.24it/s]
     85% 144736256/170498071 [00:02<00:00, 84641876.62it/s]
     90% 153583616/170498071 [00:02<00:00, 85746895.28it/s]
     95% 162529280/170498071 [00:02<00:00, 86809333.15it/s]
    100% 170498071/170498071 [00:02<00:00, 58672857.09it/s]
    Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
    Files already downloaded and verified
    2023-06-05 22:17:34,390 WARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67104768 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
    2023-06-05 22:17:34,622 INFO worker.py:1625 -- Started a local Ray instance.
    2023-06-05 22:17:35,926 INFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
    == Status ==
    Current time: 2023-06-05 22:17:39 (running for 00:00:03.68)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (9 PENDING, 1 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_c6524_00000 | RUNNING  | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |
    | train_cifar_c6524_00001 | PENDING  |                 |           16 |    1 |   16 | 0.00240134  |
    | train_cifar_c6524_00002 | PENDING  |                 |            4 |   16 |  128 | 0.00395069  |
    | train_cifar_c6524_00003 | PENDING  |                 |           16 |    4 |    8 | 0.000263916 |
    | train_cifar_c6524_00004 | PENDING  |                 |            2 |   64 |   16 | 0.0196572   |
    | train_cifar_c6524_00005 | PENDING  |                 |            4 |  256 |  128 | 0.000169702 |
    | train_cifar_c6524_00006 | PENDING  |                 |           16 |    2 |   64 | 0.000333768 |
    | train_cifar_c6524_00007 | PENDING  |                 |            8 |    8 |    8 | 0.000106119 |
    | train_cifar_c6524_00008 | PENDING  |                 |            8 |   16 |  128 | 0.000435047 |
    | train_cifar_c6524_00009 | PENDING  |                 |            8 |    8 |   64 | 0.000893815 |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2733) Files already downloaded and verified
    (func pid=2733) Files already downloaded and verified
    == Status ==
    Current time: 2023-06-05 22:17:44 (running for 00:00:08.73)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_c6524_00000 | RUNNING  | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |
    | train_cifar_c6524_00001 | RUNNING  | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |
    | train_cifar_c6524_00002 | RUNNING  | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |
    | train_cifar_c6524_00003 | RUNNING  | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |
    | train_cifar_c6524_00004 | RUNNING  | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |
    | train_cifar_c6524_00005 | RUNNING  | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |
    | train_cifar_c6524_00006 | RUNNING  | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |
    | train_cifar_c6524_00007 | RUNNING  | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |
    | train_cifar_c6524_00008 | PENDING  |                 |            8 |   16 |  128 | 0.000435047 |
    | train_cifar_c6524_00009 | PENDING  |                 |            8 |    8 |   64 | 0.000893815 |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2815) Files already downloaded and verified [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
    == Status ==
    Current time: 2023-06-05 22:17:49 (running for 00:00:13.74)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_c6524_00000 | RUNNING  | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |
    | train_cifar_c6524_00001 | RUNNING  | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |
    | train_cifar_c6524_00002 | RUNNING  | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |
    | train_cifar_c6524_00003 | RUNNING  | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |
    | train_cifar_c6524_00004 | RUNNING  | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |
    | train_cifar_c6524_00005 | RUNNING  | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |
    | train_cifar_c6524_00006 | RUNNING  | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |
    | train_cifar_c6524_00007 | RUNNING  | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |
    | train_cifar_c6524_00008 | PENDING  |                 |            8 |   16 |  128 | 0.000435047 |
    | train_cifar_c6524_00009 | PENDING  |                 |            8 |    8 |   64 | 0.000893815 |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2733) [1,  2000] loss: 2.341
    (func pid=2821) Files already downloaded and verified [repeated 6x across cluster]
    == Status ==
    Current time: 2023-06-05 22:17:54 (running for 00:00:18.75)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_c6524_00000 | RUNNING  | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |
    | train_cifar_c6524_00001 | RUNNING  | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |
    | train_cifar_c6524_00002 | RUNNING  | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |
    | train_cifar_c6524_00003 | RUNNING  | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |
    | train_cifar_c6524_00004 | RUNNING  | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |
    | train_cifar_c6524_00005 | RUNNING  | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |
    | train_cifar_c6524_00006 | RUNNING  | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |
    | train_cifar_c6524_00007 | RUNNING  | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |
    | train_cifar_c6524_00008 | PENDING  |                 |            8 |   16 |  128 | 0.000435047 |
    | train_cifar_c6524_00009 | PENDING  |                 |            8 |    8 |   64 | 0.000893815 |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2817) [1,  2000] loss: 2.325
    (func pid=2813) [1,  2000] loss: 2.020
    == Status ==
    Current time: 2023-06-05 22:17:59 (running for 00:00:23.76)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_c6524_00000 | RUNNING  | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |
    | train_cifar_c6524_00001 | RUNNING  | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |
    | train_cifar_c6524_00002 | RUNNING  | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |
    | train_cifar_c6524_00003 | RUNNING  | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |
    | train_cifar_c6524_00004 | RUNNING  | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |
    | train_cifar_c6524_00005 | RUNNING  | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |
    | train_cifar_c6524_00006 | RUNNING  | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |
    | train_cifar_c6524_00007 | RUNNING  | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |
    | train_cifar_c6524_00008 | PENDING  |                 |            8 |   16 |  128 | 0.000435047 |
    | train_cifar_c6524_00009 | PENDING  |                 |            8 |    8 |   64 | 0.000893815 |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2811) [1,  2000] loss: 2.266 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-05 22:18:04 (running for 00:00:28.77)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_c6524_00000 | RUNNING  | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |
    | train_cifar_c6524_00001 | RUNNING  | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |
    | train_cifar_c6524_00002 | RUNNING  | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |
    | train_cifar_c6524_00003 | RUNNING  | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |
    | train_cifar_c6524_00004 | RUNNING  | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |
    | train_cifar_c6524_00005 | RUNNING  | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |
    | train_cifar_c6524_00006 | RUNNING  | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |
    | train_cifar_c6524_00007 | RUNNING  | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |
    | train_cifar_c6524_00008 | PENDING  |                 |            8 |   16 |  128 | 0.000435047 |
    | train_cifar_c6524_00009 | PENDING  |                 |            8 |    8 |   64 | 0.000893815 |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    (func pid=2817) [1,  4000] loss: 1.163 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-05 22:18:09 (running for 00:00:33.79)
    Using AsyncHyperBand: num_stopped=0
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 PENDING, 8 RUNNING)
    +-------------------------+----------+-----------------+--------------+------+------+-------------+
    | Trial name              | status   | loc             |   batch_size |   l1 |   l2 |          lr |
    |-------------------------+----------+-----------------+--------------+------+------+-------------|
    | train_cifar_c6524_00000 | RUNNING  | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |
    | train_cifar_c6524_00001 | RUNNING  | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |
    | train_cifar_c6524_00002 | RUNNING  | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |
    | train_cifar_c6524_00003 | RUNNING  | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |
    | train_cifar_c6524_00004 | RUNNING  | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |
    | train_cifar_c6524_00005 | RUNNING  | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |
    | train_cifar_c6524_00006 | RUNNING  | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |
    | train_cifar_c6524_00007 | RUNNING  | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |
    | train_cifar_c6524_00008 | PENDING  |                 |            8 |   16 |  128 | 0.000435047 |
    | train_cifar_c6524_00009 | PENDING  |                 |            8 |    8 |   64 | 0.000893815 |
    +-------------------------+----------+-----------------+--------------+------+------+-------------+


    Result for train_cifar_c6524_00001:
      accuracy: 0.1937
      date: 2023-06-05_22-18-10
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 1.9875451923370362
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 26.927567958831787
      time_this_iter_s: 26.927567958831787
      time_total_s: 26.927567958831787
      timestamp: 1686003490
      training_iteration: 1
      trial_id: c6524_00001
  
    Result for train_cifar_c6524_00003:
      accuracy: 0.1283
      date: 2023-06-05_22-18-11
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 2.302567906188965
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 27.333909511566162
      time_this_iter_s: 27.333909511566162
      time_total_s: 27.333909511566162
      timestamp: 1686003491
      training_iteration: 1
      trial_id: c6524_00003
  
    Trial train_cifar_c6524_00003 completed.
    Result for train_cifar_c6524_00006:
      accuracy: 0.1986
      date: 2023-06-05_22-18-11
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 2.1561383584976195
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 27.117923259735107
      time_this_iter_s: 27.117923259735107
      time_total_s: 27.117923259735107
      timestamp: 1686003491
      training_iteration: 1
      trial_id: c6524_00006
  
    Trial train_cifar_c6524_00006 completed.
    (func pid=2815) Files already downloaded and verified
    == Status ==
    Current time: 2023-06-05 22:18:16 (running for 00:00:40.34)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1561383584976195
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      1 |          26.9276 | 1.98755 |     0.1937 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |        |                  |         |            |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |        |                  |         |            |
    | train_cifar_c6524_00007 | RUNNING    | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |        |                  |         |            |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |        |                  |         |            |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |        |                  |         |            |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2813) [1,  6000] loss: 0.564 [repeated 5x across cluster]
    (func pid=2821) Files already downloaded and verified [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-05 22:18:21 (running for 00:00:45.37)
    Using AsyncHyperBand: num_stopped=2
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.1561383584976195
    Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (8 RUNNING, 2 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      1 |          26.9276 | 1.98755 |     0.1937 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |        |                  |         |            |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |        |                  |         |            |
    | train_cifar_c6524_00007 | RUNNING    | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |        |                  |         |            |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |        |                  |         |            |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |        |                  |         |            |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00007:
      accuracy: 0.1013
      date: 2023-06-05_22-18-24
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 2.3018160514831543
      node_ip: 172.17.0.2
      pid: 2822
      should_checkpoint: true
      time_since_restore: 41.11171197891235
      time_this_iter_s: 41.11171197891235
      time_total_s: 41.11171197891235
      timestamp: 1686003504
      training_iteration: 1
      trial_id: c6524_00007
  
    Trial train_cifar_c6524_00007 completed.
    (func pid=2815) [1,  2000] loss: 2.291 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-05 22:18:29 (running for 00:00:53.79)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.228977204990387
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      1 |          26.9276 | 1.98755 |     0.1937 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |        |                  |         |            |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |        |                  |         |            |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |        |                  |         |            |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |        |                  |         |            |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2733) [1, 10000] loss: 0.469 [repeated 5x across cluster]
    Result for train_cifar_c6524_00001:
      accuracy: 0.215
      date: 2023-06-05_22-18-34
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 2
      loss: 1.8699384105682373
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 50.53286075592041
      time_this_iter_s: 23.605292797088623
      time_total_s: 50.53286075592041
      timestamp: 1686003514
      training_iteration: 2
      trial_id: c6524_00001
  
    (func pid=2821) [1,  4000] loss: 0.936 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:18:39 (running for 00:01:03.46)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -2.228977204990387
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      2 |          50.5329 | 1.86994 |     0.215  |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |        |                  |         |            |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |        |                  |         |            |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |        |                  |         |            |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |        |                  |         |            |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:18:44 (running for 00:01:08.48)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -2.228977204990387
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      2 |          50.5329 | 1.86994 |     0.215  |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |        |                  |         |            |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |        |                  |         |            |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |        |                  |         |            |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |        |                  |         |            |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2819) [1, 10000] loss: 0.395 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-06-05 22:18:49 (running for 00:01:13.49)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -2.228977204990387
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      2 |          50.5329 | 1.86994 |     0.215  |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |        |                  |         |            |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |        |                  |         |            |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |        |                  |         |            |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |        |                  |         |            |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.3715
      date: 2023-06-05_22-18-50
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 1.669931235742569
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 38.68684935569763
      time_this_iter_s: 38.68684935569763
      time_total_s: 38.68684935569763
      timestamp: 1686003530
      training_iteration: 1
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.3275
      date: 2023-06-05_22-18-50
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 1.8035070418357848
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 39.21982216835022
      time_this_iter_s: 39.21982216835022
      time_total_s: 39.21982216835022
      timestamp: 1686003530
      training_iteration: 1
      trial_id: c6524_00008
  
    Result for train_cifar_c6524_00002:
      accuracy: 0.417
      date: 2023-06-05_22-18-50
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 1.5891214286983013
      node_ip: 172.17.0.2
      pid: 2813
      should_checkpoint: true
      time_since_restore: 66.80596208572388
      time_this_iter_s: 66.80596208572388
      time_total_s: 66.80596208572388
      timestamp: 1686003530
      training_iteration: 1
      trial_id: c6524_00002
  
    == Status ==
    Current time: 2023-06-05 22:18:55 (running for 00:01:19.62)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -1.9875451923370362
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      2 |          50.5329 | 1.86994 |     0.215  |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |        |                  |         |            |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      1 |          39.2198 | 1.80351 |     0.3275 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      1 |          38.6868 | 1.66993 |     0.3715 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00005:
      accuracy: 0.2988
      date: 2023-06-05_22-18-56
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 1.9425618454933167
      node_ip: 172.17.0.2
      pid: 2819
      should_checkpoint: true
      time_since_restore: 73.0269877910614
      time_this_iter_s: 73.0269877910614
      time_total_s: 73.0269877910614
      timestamp: 1686003536
      training_iteration: 1
      trial_id: c6524_00005
  
    Result for train_cifar_c6524_00001:
      accuracy: 0.2253
      date: 2023-06-05_22-18-57
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 3
      loss: 1.8502635480880738
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 73.47706031799316
      time_this_iter_s: 22.944199562072754
      time_total_s: 73.47706031799316
      timestamp: 1686003537
      training_iteration: 3
      trial_id: c6524_00001
  
    (func pid=2733) [1, 16000] loss: 0.292 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-05 22:19:02 (running for 00:01:26.39)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -1.9650535189151763
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      3 |          73.4771 | 1.85026 |     0.2253 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      1 |          39.2198 | 1.80351 |     0.3275 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      1 |          38.6868 | 1.66993 |     0.3715 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:19:07 (running for 00:01:31.41)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -1.9650535189151763
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      3 |          73.4771 | 1.85026 |     0.2253 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      1 |          39.2198 | 1.80351 |     0.3275 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      1 |          38.6868 | 1.66993 |     0.3715 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2819) [2,  2000] loss: 1.910 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-06-05 22:19:12 (running for 00:01:36.42)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -1.9650535189151763
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      3 |          73.4771 | 1.85026 |     0.2253 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      1 |          39.2198 | 1.80351 |     0.3275 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      1 |          38.6868 | 1.66993 |     0.3715 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [2,  4000] loss: 0.753 [repeated 5x across cluster]
    == Status ==
    Current time: 2023-06-05 22:19:17 (running for 00:01:41.44)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.8699384105682373 | Iter 1.000: -1.9650535189151763
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      3 |          73.4771 | 1.85026 |     0.2253 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      1 |          39.2198 | 1.80351 |     0.3275 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      1 |          38.6868 | 1.66993 |     0.3715 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00001:
      accuracy: 0.2196
      date: 2023-06-05_22-19-19
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 4
      loss: 1.8524824213027955
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 95.87075924873352
      time_this_iter_s: 22.393698930740356
      time_total_s: 95.87075924873352
      timestamp: 1686003559
      training_iteration: 4
      trial_id: c6524_00001
  
    (func pid=2819) [2,  4000] loss: 0.921 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-05 22:19:24 (running for 00:01:48.79)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.8699384105682373 | Iter 1.000: -1.9650535189151763
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      4 |          95.8708 | 1.85248 |     0.2196 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      1 |          39.2198 | 1.80351 |     0.3275 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      1 |          38.6868 | 1.66993 |     0.3715 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.4805
      date: 2023-06-05_22-19-25
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 2
      loss: 1.423171818113327
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 74.44053363800049
      time_this_iter_s: 35.753684282302856
      time_total_s: 74.44053363800049
      timestamp: 1686003565
      training_iteration: 2
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.4342
      date: 2023-06-05_22-19-26
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 2
      loss: 1.571131125497818
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 75.58096814155579
      time_this_iter_s: 36.361145973205566
      time_total_s: 75.58096814155579
      timestamp: 1686003566
      training_iteration: 2
      trial_id: c6524_00008
  
    == Status ==
    Current time: 2023-06-05 22:19:31 (running for 00:01:55.75)
    Using AsyncHyperBand: num_stopped=3
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.571131125497818 | Iter 1.000: -1.9650535189151763
    Logical resource usage: 14.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | RUNNING    | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |        |                  |         |            |
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      4 |          95.8708 | 1.85248 |     0.2196 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      2 |          75.581  | 1.57113 |     0.4342 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      2 |          74.4405 | 1.42317 |     0.4805 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2819) [2,  6000] loss: 0.596 [repeated 3x across cluster]
    Result for train_cifar_c6524_00000:
      accuracy: 0.1043
      date: 2023-06-05_22-19-35
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 2.3673416822433473
      node_ip: 172.17.0.2
      pid: 2733
      should_checkpoint: true
      time_since_restore: 115.76354026794434
      time_this_iter_s: 115.76354026794434
      time_total_s: 115.76354026794434
      timestamp: 1686003575
      training_iteration: 1
      trial_id: c6524_00000
  
    Trial train_cifar_c6524_00000 completed.
    (func pid=2821) [3,  2000] loss: 1.407 [repeated 4x across cluster]
    == Status ==
    Current time: 2023-06-05 22:19:40 (running for 00:02:04.47)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.571131125497818 | Iter 1.000: -1.9875451923370362
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      4 |          95.8708 | 1.85248 |     0.2196 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      2 |          75.581  | 1.57113 |     0.4342 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      2 |          74.4405 | 1.42317 |     0.4805 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00001:
      accuracy: 0.2489
      date: 2023-06-05_22-19-42
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 5
      loss: 1.8146258808135987
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 118.51249670982361
      time_this_iter_s: 22.641737461090088
      time_total_s: 118.51249670982361
      timestamp: 1686003582
      training_iteration: 5
      trial_id: c6524_00001
  
    (func pid=2819) [2,  8000] loss: 0.435 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-05 22:19:47 (running for 00:02:11.44)
    Using AsyncHyperBand: num_stopped=4
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.571131125497818 | Iter 1.000: -1.9875451923370362
    Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (6 RUNNING, 4 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      5 |         118.512  | 1.81463 |     0.2489 |
    | train_cifar_c6524_00002 | RUNNING    | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      1 |          66.806  | 1.58912 |     0.417  |
    | train_cifar_c6524_00004 | RUNNING    | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |        |                  |         |            |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      2 |          75.581  | 1.57113 |     0.4342 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      2 |          74.4405 | 1.42317 |     0.4805 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00004:
      accuracy: 0.0983
      date: 2023-06-05_22-19-49
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 1
      loss: 2.3181324447155
      node_ip: 172.17.0.2
      pid: 2817
      should_checkpoint: true
      time_since_restore: 125.11955976486206
      time_this_iter_s: 125.11955976486206
      time_total_s: 125.11955976486206
      timestamp: 1686003589
      training_iteration: 1
      trial_id: c6524_00004
  
    Trial train_cifar_c6524_00004 completed.
    (func pid=2821) [3,  4000] loss: 0.689
    Result for train_cifar_c6524_00002:
      accuracy: 0.4118
      date: 2023-06-05_22-19-51
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 2
      loss: 1.6222468186676502
      node_ip: 172.17.0.2
      pid: 2813
      should_checkpoint: true
      time_since_restore: 127.17250990867615
      time_this_iter_s: 60.36654782295227
      time_total_s: 127.17250990867615
      timestamp: 1686003591
      training_iteration: 2
      trial_id: c6524_00002
  
    Trial train_cifar_c6524_00002 completed.
    (func pid=2815) [3,  4000] loss: 0.738
    == Status ==
    Current time: 2023-06-05 22:19:56 (running for 00:02:19.98)
    Using AsyncHyperBand: num_stopped=6
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.5966889720827342 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      5 |         118.512  | 1.81463 |     0.2489 |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      1 |          73.027  | 1.94256 |     0.2988 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      2 |          75.581  | 1.57113 |     0.4342 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      2 |          74.4405 | 1.42317 |     0.4805 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2811) [6,  2000] loss: 1.824 [repeated 2x across cluster]
    Result for train_cifar_c6524_00009:
      accuracy: 0.525
      date: 2023-06-05_22-19-59
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 3
      loss: 1.33847815656662
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 108.01649188995361
      time_this_iter_s: 33.575958251953125
      time_total_s: 108.01649188995361
      timestamp: 1686003599
      training_iteration: 3
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.4962
      date: 2023-06-05_22-20-00
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 3
      loss: 1.41959187707901
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 109.25848007202148
      time_this_iter_s: 33.6775119304657
      time_total_s: 109.25848007202148
      timestamp: 1686003600
      training_iteration: 3
      trial_id: c6524_00008
  
    Result for train_cifar_c6524_00005:
      accuracy: 0.3895
      date: 2023-06-05_22-20-02
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 2
      loss: 1.6731614367246628
      node_ip: 172.17.0.2
      pid: 2819
      should_checkpoint: true
      time_since_restore: 138.8141872882843
      time_this_iter_s: 65.7871994972229
      time_total_s: 138.8141872882843
      timestamp: 1686003602
      training_iteration: 2
      trial_id: c6524_00005
  
    Trial train_cifar_c6524_00005 completed.
    == Status ==
    Current time: 2023-06-05 22:20:02 (running for 00:02:26.56)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      5 |         118.512  | 1.81463 |     0.2489 |
    | train_cifar_c6524_00005 | RUNNING    | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      3 |         109.258  | 1.41959 |     0.4962 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      3 |         108.016  | 1.33848 |     0.525  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00001:
      accuracy: 0.2543
      date: 2023-06-05_22-20-02
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 6
      loss: 1.8251992267608643
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 138.92720580101013
      time_this_iter_s: 20.414709091186523
      time_total_s: 138.92720580101013
      timestamp: 1686003602
      training_iteration: 6
      trial_id: c6524_00001
  
    == Status ==
    Current time: 2023-06-05 22:20:07 (running for 00:02:31.85)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      6 |         138.927  | 1.8252  |     0.2543 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      3 |         109.258  | 1.41959 |     0.4962 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      3 |         108.016  | 1.33848 |     0.525  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [4,  2000] loss: 1.319
    (func pid=2815) [4,  2000] loss: 1.401
    == Status ==
    Current time: 2023-06-05 22:20:12 (running for 00:02:36.86)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      6 |         138.927  | 1.8252  |     0.2543 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      3 |         109.258  | 1.41959 |     0.4962 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      3 |         108.016  | 1.33848 |     0.525  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:20:17 (running for 00:02:41.87)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      6 |         138.927  | 1.8252  |     0.2543 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      3 |         109.258  | 1.41959 |     0.4962 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      3 |         108.016  | 1.33848 |     0.525  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [4,  4000] loss: 0.636 [repeated 2x across cluster]
    Result for train_cifar_c6524_00001:
      accuracy: 0.2648
      date: 2023-06-05_22-20-20
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 7
      loss: 1.7909289794921874
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 156.6013867855072
      time_this_iter_s: 17.67418098449707
      time_total_s: 156.6013867855072
      timestamp: 1686003620
      training_iteration: 7
      trial_id: c6524_00001
  
    == Status ==
    Current time: 2023-06-05 22:20:25 (running for 00:02:49.52)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.8524824213027955 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      7 |         156.601  | 1.79093 |     0.2648 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      3 |         109.258  | 1.41959 |     0.4962 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      3 |         108.016  | 1.33848 |     0.525  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.5583
      date: 2023-06-05_22-20-27
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 4
      loss: 1.2371150862216949
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 135.97530913352966
      time_this_iter_s: 27.95881724357605
      time_total_s: 135.97530913352966
      timestamp: 1686003627
      training_iteration: 4
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.5128
      date: 2023-06-05_22-20-28
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 4
      loss: 1.3740191452026367
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 137.70287013053894
      time_this_iter_s: 28.444390058517456
      time_total_s: 137.70287013053894
      timestamp: 1686003628
      training_iteration: 4
      trial_id: c6524_00008
  
    (func pid=2811) [8,  2000] loss: 1.793 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:20:33 (running for 00:02:57.87)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: None | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      7 |         156.601  | 1.79093 |     0.2648 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      4 |         137.703  | 1.37402 |     0.5128 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      4 |         135.975  | 1.23712 |     0.5583 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00001:
      accuracy: 0.2695
      date: 2023-06-05_22-20-38
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 8
      loss: 1.7807931131362915
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 174.4365155696869
      time_this_iter_s: 17.835128784179688
      time_total_s: 174.4365155696869
      timestamp: 1686003638
      training_iteration: 8
      trial_id: c6524_00001
  
    (func pid=2815) [5,  2000] loss: 1.310 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:20:43 (running for 00:03:07.36)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      8 |         174.437  | 1.78079 |     0.2695 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      4 |         137.703  | 1.37402 |     0.5128 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      4 |         135.975  | 1.23712 |     0.5583 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [5,  4000] loss: 0.615
    (func pid=2815) [5,  4000] loss: 0.648
    == Status ==
    Current time: 2023-06-05 22:20:48 (running for 00:03:12.37)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      8 |         174.437  | 1.78079 |     0.2695 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      4 |         137.703  | 1.37402 |     0.5128 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      4 |         135.975  | 1.23712 |     0.5583 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:20:53 (running for 00:03:17.38)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      8 |         174.437  | 1.78079 |     0.2695 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      4 |         137.703  | 1.37402 |     0.5128 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      4 |         135.975  | 1.23712 |     0.5583 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.5691
      date: 2023-06-05_22-20-55
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 5
      loss: 1.1933141448020934
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 163.62633419036865
      time_this_iter_s: 27.65102505683899
      time_total_s: 163.62633419036865
      timestamp: 1686003655
      training_iteration: 5
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00001:
      accuracy: 0.2546
      date: 2023-06-05_22-20-56
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 9
      loss: 1.824686025238037
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 192.34015774726868
      time_this_iter_s: 17.903642177581787
      time_total_s: 192.34015774726868
      timestamp: 1686003656
      training_iteration: 9
      trial_id: c6524_00001
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.5197
      date: 2023-06-05_22-20-56
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 5
      loss: 1.3604125372171403
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 165.5668706893921
      time_this_iter_s: 27.86400055885315
      time_total_s: 165.5668706893921
      timestamp: 1686003656
      training_iteration: 5
      trial_id: c6524_00008
  
    == Status ==
    Current time: 2023-06-05 22:21:01 (running for 00:03:25.72)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      9 |         192.34   | 1.82469 |     0.2546 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      5 |         165.567  | 1.36041 |     0.5197 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      5 |         163.626  | 1.19331 |     0.5691 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [6,  2000] loss: 1.194 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:21:06 (running for 00:03:30.73)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      9 |         192.34   | 1.82469 |     0.2546 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      5 |         165.567  | 1.36041 |     0.5197 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      5 |         163.626  | 1.19331 |     0.5691 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:21:11 (running for 00:03:35.74)
    Using AsyncHyperBand: num_stopped=7
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 6.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00001 | RUNNING    | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |      9 |         192.34   | 1.82469 |     0.2546 |
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      5 |         165.567  | 1.36041 |     0.5197 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      5 |         163.626  | 1.19331 |     0.5691 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00001:
      accuracy: 0.2718
      date: 2023-06-05_22-21-13
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 10
      loss: 1.7663614246368409
      node_ip: 172.17.0.2
      pid: 2811
      should_checkpoint: true
      time_since_restore: 209.93620586395264
      time_this_iter_s: 17.59604811668396
      time_total_s: 209.93620586395264
      timestamp: 1686003673
      training_iteration: 10
      trial_id: c6524_00001
  
    Trial train_cifar_c6524_00001 completed.
    (func pid=2821) [6,  4000] loss: 0.589 [repeated 3x across cluster]
    == Status ==
    Current time: 2023-06-05 22:21:18 (running for 00:03:42.87)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      5 |         165.567  | 1.36041 |     0.5197 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      5 |         163.626  | 1.19331 |     0.5691 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.5696
      date: 2023-06-05_22-21-21
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 6
      loss: 1.192466367483139
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 190.5135943889618
      time_this_iter_s: 26.88726019859314
      time_total_s: 190.5135943889618
      timestamp: 1686003681
      training_iteration: 6
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.5655
      date: 2023-06-05_22-21-24
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 6
      loss: 1.2196064559459687
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 192.8128490447998
      time_this_iter_s: 27.245978355407715
      time_total_s: 192.8128490447998
      timestamp: 1686003684
      training_iteration: 6
      trial_id: c6524_00008
  
    == Status ==
    Current time: 2023-06-05 22:21:24 (running for 00:03:47.96)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      6 |         192.813  | 1.21961 |     0.5655 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      6 |         190.514  | 1.19247 |     0.5696 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:21:29 (running for 00:03:52.97)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      6 |         192.813  | 1.21961 |     0.5655 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      6 |         190.514  | 1.19247 |     0.5696 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [7,  2000] loss: 1.151 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:21:34 (running for 00:03:57.98)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      6 |         192.813  | 1.21961 |     0.5655 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      6 |         190.514  | 1.19247 |     0.5696 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:21:39 (running for 00:04:02.99)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      6 |         192.813  | 1.21961 |     0.5655 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      6 |         190.514  | 1.19247 |     0.5696 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [7,  4000] loss: 0.585 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:21:44 (running for 00:04:08.00)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      6 |         192.813  | 1.21961 |     0.5655 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      6 |         190.514  | 1.19247 |     0.5696 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.572
      date: 2023-06-05_22-21-47
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 7
      loss: 1.1934200815677642
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 216.08805322647095
      time_this_iter_s: 25.574458837509155
      time_total_s: 216.08805322647095
      timestamp: 1686003707
      training_iteration: 7
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.573
      date: 2023-06-05_22-21-49
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 7
      loss: 1.215738592505455
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 218.734849691391
      time_this_iter_s: 25.922000646591187
      time_total_s: 218.734849691391
      timestamp: 1686003709
      training_iteration: 7
      trial_id: c6524_00008
  
    == Status ==
    Current time: 2023-06-05 22:21:49 (running for 00:04:13.89)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      7 |         218.735  | 1.21574 |     0.573  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      7 |         216.088  | 1.19342 |     0.572  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:21:54 (running for 00:04:18.90)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      7 |         218.735  | 1.21574 |     0.573  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      7 |         216.088  | 1.19342 |     0.572  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [8,  2000] loss: 1.126 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:21:59 (running for 00:04:23.91)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      7 |         218.735  | 1.21574 |     0.573  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      7 |         216.088  | 1.19342 |     0.572  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:22:04 (running for 00:04:28.91)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      7 |         218.735  | 1.21574 |     0.573  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      7 |         216.088  | 1.19342 |     0.572  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [8,  4000] loss: 0.567 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:22:09 (running for 00:04:33.92)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.7807931131362915 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      7 |         218.735  | 1.21574 |     0.573  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      7 |         216.088  | 1.19342 |     0.572  |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.5867
      date: 2023-06-05_22-22-13
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 8
      loss: 1.1561152244567872
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 241.77858543395996
      time_this_iter_s: 25.690532207489014
      time_total_s: 241.77858543395996
      timestamp: 1686003733
      training_iteration: 8
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.601
      date: 2023-06-05_22-22-16
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 8
      loss: 1.1407612905979156
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 244.85198950767517
      time_this_iter_s: 26.11713981628418
      time_total_s: 244.85198950767517
      timestamp: 1686003736
      training_iteration: 8
      trial_id: c6524_00008
  
    == Status ==
    Current time: 2023-06-05 22:22:16 (running for 00:04:40.00)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      8 |         244.852  | 1.14076 |     0.601  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      8 |         241.779  | 1.15612 |     0.5867 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:22:21 (running for 00:04:45.02)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      8 |         244.852  | 1.14076 |     0.601  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      8 |         241.779  | 1.15612 |     0.5867 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [9,  2000] loss: 1.109 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:22:26 (running for 00:04:50.03)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      8 |         244.852  | 1.14076 |     0.601  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      8 |         241.779  | 1.15612 |     0.5867 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [9,  4000] loss: 0.561 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:22:31 (running for 00:04:55.04)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      8 |         244.852  | 1.14076 |     0.601  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      8 |         241.779  | 1.15612 |     0.5867 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:22:36 (running for 00:05:00.05)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      8 |         244.852  | 1.14076 |     0.601  |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      8 |         241.779  | 1.15612 |     0.5867 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.5894
      date: 2023-06-05_22-22-38
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 9
      loss: 1.1491562018871306
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 267.43716526031494
      time_this_iter_s: 25.65857982635498
      time_total_s: 267.43716526031494
      timestamp: 1686003758
      training_iteration: 9
      trial_id: c6524_00009
  
    Result for train_cifar_c6524_00008:
      accuracy: 0.5987
      date: 2023-06-05_22-22-42
      done: false
      hostname: d54a06041d2c
      iterations_since_restore: 9
      loss: 1.1482283054828644
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 271.3173756599426
      time_this_iter_s: 26.465386152267456
      time_total_s: 271.3173756599426
      timestamp: 1686003762
      training_iteration: 9
      trial_id: c6524_00008
  
    == Status ==
    Current time: 2023-06-05 22:22:42 (running for 00:05:06.47)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      9 |         271.317  | 1.14823 |     0.5987 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      9 |         267.437  | 1.14916 |     0.5894 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:22:47 (running for 00:05:11.48)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      9 |         271.317  | 1.14823 |     0.5987 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      9 |         267.437  | 1.14916 |     0.5894 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [10,  2000] loss: 1.091 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:22:52 (running for 00:05:16.49)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      9 |         271.317  | 1.14823 |     0.5987 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      9 |         267.437  | 1.14916 |     0.5894 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    (func pid=2821) [10,  4000] loss: 0.549 [repeated 2x across cluster]
    == Status ==
    Current time: 2023-06-05 22:22:57 (running for 00:05:21.50)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      9 |         271.317  | 1.14823 |     0.5987 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      9 |         267.437  | 1.14916 |     0.5894 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:23:02 (running for 00:05:26.51)
    Using AsyncHyperBand: num_stopped=8
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |      9 |         271.317  | 1.14823 |     0.5987 |
    | train_cifar_c6524_00009 | RUNNING    | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |      9 |         267.437  | 1.14916 |     0.5894 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    Result for train_cifar_c6524_00009:
      accuracy: 0.5838
      date: 2023-06-05_22-23-04
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 10
      loss: 1.1555669220924378
      node_ip: 172.17.0.2
      pid: 2821
      should_checkpoint: true
      time_since_restore: 293.1641628742218
      time_this_iter_s: 25.72699761390686
      time_total_s: 293.1641628742218
      timestamp: 1686003784
      training_iteration: 10
      trial_id: c6524_00009
  
    Trial train_cifar_c6524_00009 completed.
    Result for train_cifar_c6524_00008:
      accuracy: 0.5994
      date: 2023-06-05_22-23-08
      done: true
      hostname: d54a06041d2c
      iterations_since_restore: 10
      loss: 1.1314307451605796
      node_ip: 172.17.0.2
      pid: 2815
      should_checkpoint: true
      time_since_restore: 297.17096304893494
      time_this_iter_s: 25.85358738899231
      time_total_s: 297.17096304893494
      timestamp: 1686003788
      training_iteration: 10
      trial_id: c6524_00008
  
    Trial train_cifar_c6524_00008 completed.
    == Status ==
    Current time: 2023-06-05 22:23:08 (running for 00:05:32.32)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00008 | RUNNING    | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |     10 |         297.171  | 1.13143 |     0.5994 |
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    | train_cifar_c6524_00009 | TERMINATED | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |     10 |         293.164  | 1.15557 |     0.5838 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    == Status ==
    Current time: 2023-06-05 22:23:08 (running for 00:05:32.33)
    Using AsyncHyperBand: num_stopped=10
    Bracket: Iter 8.000: -1.1561152244567872 | Iter 4.000: -1.3740191452026367 | Iter 2.000: -1.6222468186676502 | Iter 1.000: -2.0718417754173277
    Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:M60)
    Result logdir: /var/lib/jenkins/ray_results/train_cifar_2023-06-05_22-17-35
    Number of trials: 10/10 (10 TERMINATED)
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+
    | Trial name              | status     | loc             |   batch_size |   l1 |   l2 |          lr |   iter |   total time (s) |    loss |   accuracy |
    |-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------|
    | train_cifar_c6524_00000 | TERMINATED | 172.17.0.2:2733 |            2 |    2 |    2 | 0.0372471   |      1 |         115.764  | 2.36734 |     0.1043 |
    | train_cifar_c6524_00001 | TERMINATED | 172.17.0.2:2811 |           16 |    1 |   16 | 0.00240134  |     10 |         209.936  | 1.76636 |     0.2718 |
    | train_cifar_c6524_00002 | TERMINATED | 172.17.0.2:2813 |            4 |   16 |  128 | 0.00395069  |      2 |         127.173  | 1.62225 |     0.4118 |
    | train_cifar_c6524_00003 | TERMINATED | 172.17.0.2:2815 |           16 |    4 |    8 | 0.000263916 |      1 |          27.3339 | 2.30257 |     0.1283 |
    | train_cifar_c6524_00004 | TERMINATED | 172.17.0.2:2817 |            2 |   64 |   16 | 0.0196572   |      1 |         125.12   | 2.31813 |     0.0983 |
    | train_cifar_c6524_00005 | TERMINATED | 172.17.0.2:2819 |            4 |  256 |  128 | 0.000169702 |      2 |         138.814  | 1.67316 |     0.3895 |
    | train_cifar_c6524_00006 | TERMINATED | 172.17.0.2:2821 |           16 |    2 |   64 | 0.000333768 |      1 |          27.1179 | 2.15614 |     0.1986 |
    | train_cifar_c6524_00007 | TERMINATED | 172.17.0.2:2822 |            8 |    8 |    8 | 0.000106119 |      1 |          41.1117 | 2.30182 |     0.1013 |
    | train_cifar_c6524_00008 | TERMINATED | 172.17.0.2:2815 |            8 |   16 |  128 | 0.000435047 |     10 |         297.171  | 1.13143 |     0.5994 |
    | train_cifar_c6524_00009 | TERMINATED | 172.17.0.2:2821 |            8 |    8 |   64 | 0.000893815 |     10 |         293.164  | 1.15557 |     0.5838 |
    +-------------------------+------------+-----------------+--------------+------+------+-------------+--------+------------------+---------+------------+


    2023-06-05 22:23:08,399 INFO tune.py:945 -- Total run time: 332.47 seconds (332.33 seconds for the tuning loop).
    Best trial config: {'l1': 16, 'l2': 128, 'lr': 0.00043504743054514883, 'batch_size': 8}
    Best trial final validation loss: 1.1314307451605796
    Best trial final validation accuracy: 0.5994
    Files already downloaded and verified
    Files already downloaded and verified
    Best trial test set accuracy: 0.6011




.. GENERATED FROM PYTHON SOURCE LINES 463-493

If you run the code, an example output could look like this:

::

    Number of trials: 10/10 (10 TERMINATED)
    +-----+--------------+------+------+-------------+--------+---------+------------+
    | ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |
    |-----+--------------+------+------+-------------+--------+---------+------------|
    | ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |
    | ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |
    | ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |
    | ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |
    | ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |
    | ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |
    | ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |
    | ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |
    | ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |
    | ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |
    +-----+--------------+------+------+-------------+--------+---------+------------+

    Best trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}
    Best trial final validation loss: 1.5310075663924216
    Best trial final validation accuracy: 0.4761
    Best trial test set accuracy: 0.4737

Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 47%, which could
be confirmed on the test set.

So that's it! You can now tune the parameters of your PyTorch models.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 5 minutes  50.299 seconds)


.. _sphx_glr_download_beginner_hyperparameter_tuning_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: hyperparameter_tuning_tutorial.py <hyperparameter_tuning_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: hyperparameter_tuning_tutorial.ipynb <hyperparameter_tuning_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
